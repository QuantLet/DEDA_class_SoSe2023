{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4083d724-f909-493a-a034-dd344d1e6bbb",
   "metadata": {},
   "source": [
    "# **Welcome to the Demo Notebook for Webscraping**\n",
    "\n",
    "In this demo notebook we go through the `thesis_scraper.py` module used in the project and demonstrate its functionality.<br>\n",
    "\n",
    "**Disclaimer:** The notebook was run by the authors on the \"mavis\" computing server (1024 GB memory; 40 physical cores at 3.1 GHz) of the Humboldt Lab for Empirical and Quantitative Research. Execution time may be significantly longer for other users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948788c-2ff8-48b9-a808-dd2a9fc8a07b",
   "metadata": {},
   "source": [
    "### **The Dependencies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5b33e-e2e1-41f1-bcf5-022d12ea2adb",
   "metadata": {},
   "source": [
    "First  import some basic libraries and then install the requirements to set up the environment needed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe9aeb1-d446-43eb-bca6-be99779e42f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# Custom function to measure runtime\n",
    "from measure_time import measure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca099084-e569-4fca-8de2-ff2096d19edb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Seafile\\\\Моя библиотека\\\\2 semester\\\\DEDA\\\\GitHub\\\\Bacha fork\\\\DEDA_class_SoSe2023\\\\DEDA_class_SoSe2023_LDA_Theses\\\\DEDA_class_SoSe2023_LDA_MSc_Theses\\\\LDA_MSc_1_Webscraping'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d27be-1aeb-4c9b-a32c-b59242231dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Requirements\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3cf24-3fe6-44e9-a228-6a0076bfb06a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **The Scraper**\n",
    "Import the master_theses_scraper from the  added `thesis_scraper.py` module, docstring of which is given below. The function is constructed deliberately to produce many `print()` statements along the way to let the users know what stage of the work they are on and how this or that entry currently being processed looks like.\n",
    "\n",
    "Also, to note, the scraping implementation is designed in a way that is specifically targeted at the HU website, meaning it will need some tinkering inside for repurposing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b507cbd8-aa1f-4ba4-bc3e-8aa71e5df07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mmaster_theses_scraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdown_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Scrapes master's theses from a specified URL, retrieves download links, and downloads the theses.\n",
       "\n",
       "Args:\n",
       "    url (str): The URL of the webpage containing the LvB theses.\n",
       "    down_dir (str): The directory where the scraped PDFs will be downloaded.\n",
       "    headers (dict): HTTP headers to be used in the requests.\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\seafile\\моя библиотека\\2 semester\\deda\\github\\bacha fork\\deda_class_sose2023\\deda_class_sose2023_lda_theses\\deda_class_sose2023_lda_msc_theses\\lda_msc_1_webscraping\\thesis_scraper.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the custom function and inspect\n",
    "from thesis_scraper import master_theses_scraper \n",
    "master_theses_scraper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ae1f44-eca1-4188-b3c0-4414c13ffa39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the link to scrape\n",
    "url = 'https://www.wiwi.hu-berlin.de/de/forschung/irtg/lvb/research/dmb'\n",
    "\n",
    "# Sets the directory for downloading our scraped pdfs\n",
    "down_dir = 'OCRed PDFs/'\n",
    "\n",
    "# Makes the directory in case it does not exist already\n",
    "os.makedirs(down_dir, exist_ok = True)\n",
    "\n",
    "\n",
    "# Set your own user agent here\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'en-US'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fd66d1-e7fd-42b3-8368-c7976ed63205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Web page accessed.\n",
      "\n",
      "244 entries found.\n",
      "\n",
      "An example entry in our links container looks like:\n",
      " <a data-linktype=\"external\" data-val=\"https://edoc.hu-berlin.de/handle/18452/24455\" href=\"https://edoc.hu-berlin.de/handle/18452/24455\">Comparing Cryptocurrency Indices to Traditional Indices</a>\n",
      "\n",
      "Identifying invalid links...\n",
      "\n",
      "51 invalid links identified.\n",
      "\n",
      "193 entries remain.\n",
      "\n",
      "Identifying Master's Theses...\n",
      "\n",
      "124 Master's Theses identified.\n",
      "\n",
      "A sample entry looks as follows:\n",
      " <a href=\"https://edoc.hu-berlin.de/handle/18452/23881\">App-based Forecasting of CRIX Index Returns Using R and R-Shiny</a>\n",
      "\n",
      "Retrieving download links...\n",
      "\n",
      "Due to missing link, dropped entry: <a href=\"http://edoc.hu-berlin.de/master/ristig-alexander-2012-02-03\">Modelling of Vector MEM with Hierarchical Archimedean Copula</a>\n",
      "\n",
      "Due to missing link, dropped entry: <a href=\"http://edoc.hu-berlin.de/master/schelisch-martin-2011-06-10\">Jumps in High Frequency Data</a>\n",
      "\n",
      "Due to missing link, dropped entry: <a href=\"http://edoc.hu-berlin.de/master/pinosa-anna-2010-09-18\">Statistische Auswertung der Fehler in den Statistik-Klausuren</a>\n",
      "\n",
      "Retrieval complete.\n",
      "\n",
      "An example of our link looks like:\n",
      " https://edoc.hu-berlin.de/bitstream/handle/18452/23881/master_garcia_gonzalo.pdf?sequence=3&isAllowed=y\n",
      "\n",
      "We can download 121 Master's Theses in total.\n",
      "\n",
      "Download in progress...\n",
      "\n",
      "Download Complete\n",
      "\n",
      "Execution time: 0 hours 7 minutes 50 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set begginning time \n",
    "st = time.time()\n",
    "\n",
    "# Run the function:\n",
    "master_theses_scraper(url = url,\n",
    "                      down_dir = down_dir,\n",
    "                      headers = headers\n",
    ")\n",
    "\n",
    "# Measure time spent on execution of the function\n",
    "measure_time(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d182ca5-1ec6-4a01-aadc-a306cba85e3a",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Physically stored MSc theses have also been added, so we manually added information about them in the `thesis_info.pkl`.\n",
    "\n",
    "This was done with the following code:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# Unpickling data from Corpus Maker\n",
    "\n",
    "with open('thesis_info.pkl', 'rb') as file:\n",
    "    thesis_info = pickle.load(file)\n",
    "    \n",
    "#adding physically stored theses\n",
    "added_theses={\n",
    "    'Alexander Hölzer_2022-07-25.pdf': ['Supervised Machine Learning Sentiment Measures', 'Hölzer, Alexander'],\n",
    "    'Franziska Sabine Wehrmann_2021-08-08.pdf': ['Trading Strategies for Bitcoin Options based on Deviations in Risk Neutral and Historical Densities', 'Wehrmann, Franziska Sabine'],\n",
    "    'Ivan Kotik_2022-09-28.pdf': ['Indexing, interfaces & searching in dynamic knowledge platforms', 'Kotik, Ivan'],\n",
    "    'Judith Bender_2022-08-05.pdf': ['Portfolio Diversification based on Risk Profile Clustering', 'Bender, Judith'],\n",
    "    'Kevin Noessler_2020-11-12.pdf': ['In search for stability in crypto-assets: An Index-Pegged Stablecoin', 'Noessler, Kevin'],\n",
    "    'Lucas Valentin Umann_2023-02-13.pdf': ['Blockchain Characteristics and Systematic Risk: A Neural Network Based Factor Model for Cryptocurrencies', 'Umann, Lucas Valentin'],\n",
    "    'Man Yuan_2022-11-10.pdf': ['Private Equity Premium Puzzle Revisited with Beta Coefficient', 'Yuan, Man'],\n",
    "    'Marius Sterling_2020-03-07.pdf': ['Forecasting Stock Prices of Limit Order Book Data with Deep Neural Networks', \"Sterling, Marius\"],\n",
    "    'Thomas Georg Herrdum_2020-11-04.pdf': ['CRIX the Coin: A Crypto Collateralized Index Coin', 'Herrdum, Thomas Geord'],\n",
    "    'Xun Gong_2020-01-21.pdf': ['Personalized Recipe Recommender System using Recurrent Neural Network', 'Gong, Xun'],\n",
    "    'Yarong Yang_2021-12-10.pdf': ['The Financial Risk Meter and its application for Singapore', 'Yang, Yarong']\n",
    "}\n",
    "\n",
    "thesis_info.update(added_theses)\n",
    "\n",
    "#editing filename for a cropped thesis (see notes in LDA_MSc_2_Preprocessing.ipynb) \n",
    "thesis_info['aydinli cropped_2004-07-15.pdf'] = thesis_info.pop('113.aydinli.pdf_2004-07-15.pdf')\n",
    "\n",
    "#saving the updated pickle file\n",
    "with open('thesis_info.pkl', 'wb') as file:\n",
    "    pickle.dump(thesis_info, file)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
