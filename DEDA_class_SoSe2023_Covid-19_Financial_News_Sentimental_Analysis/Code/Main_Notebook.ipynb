{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QOr6mO9rEq5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGpe9K6ArEPs"
      },
      "outputs": [],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgEFhKRaq-_H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import random as rd\n",
        "import time\n",
        "from wordcloud import WordCloud\n",
        "import os\n",
        "from google.colab import files\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_YCRRRJrd9c"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glycsXH3rdom"
      },
      "outputs": [],
      "source": [
        "# for new index of a data frame:\n",
        "def ind(df):\n",
        "  length = len(df)\n",
        "  df_range = range(length)\n",
        "  return df_range\n",
        "\n",
        "# the following functions give back a list of data frames\n",
        "# function for searching after keywords in a data frame\n",
        "def kw_func(df,kw):\n",
        "  index = df[df['Text'].str.contains('|'.join(kw), case=False)].index\n",
        "  new_df = df.loc[index]\n",
        "  ni = range(len(new_df))\n",
        "  new_df.index = ni\n",
        "  return new_df\n",
        "\n",
        "# putting the data frames in a list from the function above\n",
        "def lst_kws(df,kws):\n",
        "  lst = []\n",
        "  for kw in kws:\n",
        "    ind = pd.DataFrame(kw_func(df,kw))\n",
        "    lst.append(ind)\n",
        "  return lst\n",
        "\n",
        "# function for sentimental analysis\n",
        "def sa(df,kws):\n",
        "  lst = lst_kws(df,kws)\n",
        "  # only using for new_dataframe\n",
        "  for d in lst:\n",
        "    # Initialize the sentiment analyzer\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Create an empty list to store sentiment labels\n",
        "    sentiment_labels = []\n",
        "\n",
        "    # Perform sentiment analysis on the text\n",
        "    sent_lambda = lambda text: analyzer.polarity_scores(text)[\"compound\"]\n",
        "    d['Sentiment'] = d['Text'].apply(sent_lambda)\n",
        "    for i in range(len(d)):\n",
        "      if d.at[i,'Sentiment'] >= 0.05:\n",
        "        sentiment_labels.append('Positive')\n",
        "      elif d.at[i,'Sentiment'] <= -0.05:\n",
        "        sentiment_labels.append('Negative')\n",
        "      else:\n",
        "        sentiment_labels.append('Neutral')\n",
        "    d['Sentiment Label'] = sentiment_labels\n",
        "  return lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeOW_Zc3roWV"
      },
      "source": [
        "# Stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BT6--zFrp5c"
      },
      "outputs": [],
      "source": [
        "# tickers\n",
        "aaple = 'AAPL'\n",
        "google = 'GOOG' # Alphabet cop.\n",
        "microsoft = 'MSFT'\n",
        "pfizer = 'PFE'\n",
        "\n",
        "# start and end date\n",
        "start = '2020-01-01'\n",
        "end = '2023-01-01'\n",
        "\n",
        "# Downloading Stock data\n",
        "apl = yf.download(aaple,start=start,end=end)\n",
        "goog = yf.download(google,start=start,end=end)\n",
        "ms = yf.download(microsoft,start=start,end=end)\n",
        "pfe = yf.download(pfizer,start=start,end=end)\n",
        "\n",
        "# date column\n",
        "apl['Date'] = apl.index.date\n",
        "goog['Date'] = goog.index.date\n",
        "ms['Date'] = ms.index.date\n",
        "pfe['Date'] = pfe.index.date\n",
        "\n",
        "\n",
        "# Put downloaded data in data frames\n",
        "apl = pd.DataFrame(apl)\n",
        "goog = pd.DataFrame(goog)\n",
        "ms = pd.DataFrame(ms)\n",
        "pfe = pd.DataFrame(pfe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tqj83AiupVn"
      },
      "source": [
        "If the code doesn't work for download the stocks data, use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noaUvFILv3-C"
      },
      "outputs": [],
      "source": [
        "# # Getting data\n",
        "# !wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/Stocks/AAPL_Stock_Data.zip\n",
        "# !wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/Stocks/GOOG_Stock_Data.zip\n",
        "# !wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/Stocks/MSFT_Stock_Data.zip\n",
        "# !wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/Stocks/PFE_Stock_Data.zip\n",
        "\n",
        "# # Unzip the files:\n",
        "# !unzip AAPL_Stock_Data.zip\n",
        "# !unzip GOOG_Stock_Data.zip\n",
        "# !unzip MSFT_Stock_Data.zip\n",
        "# !unzip PFE_Stock_Data.zip\n",
        "\n",
        "# # Put in Data Frames:\n",
        "# apl = pd.read_csv('AAPL_Stock_Data.csv')\n",
        "# goog = pd.read_csv('GOOG_Stock_Data.csv')\n",
        "# ms = pd.read_csv('MSFT_Stock_Data.csv')\n",
        "# pfe = pd.read_csv('PFE_Stock_Data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql3iJyc12WzT"
      },
      "source": [
        "Plot the stock data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnarB2vaxlL_"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "apl['Close'].plot(label='Apple')\n",
        "goog['Close'].plot(label='Google')\n",
        "ms['Close'].plot(label='Microsoft')\n",
        "pfe['Close'].plot(label='Pfizer')\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25), ncol=2)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Stocks in Time Series')\n",
        "plt.savefig('timeseriesstocks.png', dpi=500, transparent=True,bbox_inches = 'tight')\n",
        "\n",
        "fig.patch.set_alpha(0.0)\n",
        "ax.patch.set_alpha(0.0)\n",
        "\n",
        "# plt.show()\n",
        "# plt.savefig('Stocks.png',dpi=fig.dpi,transparent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO3tD0GXxprc"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "pfe['Close'].plot(label='Pfizer', color='red')\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25), ncol=2)\n",
        "fig.patch.set_alpha(0.0)\n",
        "ax.patch.set_alpha(0.0)\n",
        "plt.savefig('Pfizer.png',dpi=600,bbox_inches = 'tight',transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PhRAi7hx7JE"
      },
      "source": [
        "# Data\n",
        "Getting the data from github. For getting the data from Kaggle, please look at the notebook Data-Manipulation-1.ipynb. For data preparation for sentimental analysis please look at the notebook Data-Manipulation-2.ipynb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c3GiTc0bzEeL"
      },
      "outputs": [],
      "source": [
        "# Download prepared data for sentimental analysis\n",
        "!wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/SA-Data/CNBC-SA.zip\n",
        "!wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/SA-Data/CNN-SA.zip\n",
        "!wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/SA-Data/NYT-SA.zip\n",
        "!wget https://github.com/QuantLet/DEDA_class_SoSe2023/raw/main/DEDA_class_SoSe2023_Covid-19_Financial_News_Sentimental_Analysis/Data/SA-Data/YSP-SA.zip\n",
        "\n",
        "# Unzip the files\n",
        "!unzip CNBC-SA.zip\n",
        "!unzip CNN-SA.zip\n",
        "!unzip YSP-SA.zip\n",
        "!unzip NYT-SA.zip\n",
        "\n",
        "# put data in data frames\n",
        "new_cnbc = pd.read_csv('CNBC-SA.csv')\n",
        "new_cnn = pd.read_csv('CNN-SA.csv')\n",
        "new_nyt = pd.read_csv('NYT-SA.csv')\n",
        "new_ysp = pd.read_csv('YSP-SA.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_6-d7AT0HeY"
      },
      "outputs": [],
      "source": [
        "# keywords\n",
        "kw_cor = [\n",
        "          'corona', 'virus','mask',\n",
        "          'pandemic','isolation','self isolation',\n",
        "          'social distance', 'covid', 'covid-19',\n",
        "          'covid 19', 'formite', 'epidemic','outbreak',\n",
        "          'contact tracing', 'martial law', 'self quarantine',\n",
        "          'quarantine',\n",
        "          'super spreader', 'contagious', 'infectious'\n",
        "          ]\n",
        "kw_ap = ['apple']\n",
        "kw_pf = ['pfizer']\n",
        "kw_ms = ['microsoft']\n",
        "kw_gg = ['google']\n",
        "kws = [kw_cor, kw_ap, kw_pf,kw_ms,kw_gg]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5IwHw100NG3"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZATuYemR0QjH"
      },
      "outputs": [],
      "source": [
        "# Sentiment Analysis\n",
        "sa_cnbc = sa(new_cnbc,kws)\n",
        "sa_cnn = sa(new_cnn,kws)\n",
        "sa_ysp = sa(new_ysp,kws)\n",
        "sa_nyt = sa(new_nyt,kws)\n",
        "\n",
        "# putting data frames into a list\n",
        "super_sa = [sa_cnbc,sa_cnn,sa_ysp,sa_nyt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3F-XSIA0XL-"
      },
      "outputs": [],
      "source": [
        "# change data frames colum Date the data type\n",
        "for i in range(len(super_sa)):\n",
        "    for j in range(len(super_sa[i])):\n",
        "        super_sa[i][j]['Date'] = pd.DatetimeIndex(super_sa[i][j]['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h09uWto43YQ"
      },
      "source": [
        "# Word Cloud\n",
        "Using our defined keywords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zkq0gb56LAy"
      },
      "source": [
        "## CNBC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKIw2yva45Pz"
      },
      "outputs": [],
      "source": [
        "# # Define the keywords\n",
        "# kw = [kw_cor, kw_ap, kw_pf,kw_ms,kw_gg]\n",
        "\n",
        "# # Initialize the sentiment analyzer\n",
        "# analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# # Create an empty DataFrame to store sentiment data\n",
        "# sentiment_data_cnbc = pd.DataFrame(columns=['Text', 'Compound Sentiment Score', 'Date', 'Keywords'])\n",
        "\n",
        "# # Create an empty list to store sentiment labels\n",
        "# sentiment_labels = []\n",
        "\n",
        "# # Iterate over the keywords\n",
        "# for keyword in kw:\n",
        "\n",
        "#     # Iterate over each row in the DataFrame\n",
        "#     for index, row in new_cnbc.iterrows():\n",
        "#         # Extract the text and date from the row\n",
        "#         text = str(row['Text'])\n",
        "#         date_str = row['Date']\n",
        "\n",
        "#         # Perform sentiment analysis on the text\n",
        "#         sentiment = analyzer.polarity_scores(text)\n",
        "#         compound_score = sentiment[\"compound\"]\n",
        "\n",
        "#         # Check if the keyword is mentioned in the text\n",
        "#         mentioned_keywords = [kw for kw in keyword if kw.lower() in text.lower()]\n",
        "\n",
        "#         # Create a DataFrame for the current row\n",
        "#         row_data = pd.DataFrame({'Text': [text], 'Compound Sentiment Score': [compound_score], 'Date': [date_str],\n",
        "#                                  'Keywords': [mentioned_keywords]})\n",
        "\n",
        "#         # Concatenate the current row DataFrame with the sentiment_data DataFrame\n",
        "#         sentiment_data_cnbc = pd.concat([sentiment_data_cnbc, row_data], ignore_index=True)\n",
        "\n",
        "#         # Assign a label based on the compound score\n",
        "#         if compound_score >= 0.05:\n",
        "#             sentiment_labels.append('Positive')\n",
        "#         elif compound_score <= -0.05:\n",
        "#             sentiment_labels.append('Negative')\n",
        "#         else:\n",
        "#             sentiment_labels.append('Neutral')\n",
        "\n",
        "# # Add the sentiment labels to the DataFrame\n",
        "# sentiment_data_cnbc['Sentiment Label'] = sentiment_labels\n",
        "\n",
        "# # Print the sentiment data DataFrame\n",
        "# # print(sentiment_data_cnbc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT3M9F_zMDFr"
      },
      "outputs": [],
      "source": [
        "# sentiment_data_cnbc.to_csv('SA-CNBC.csv',encoding='utf-8-sig')\n",
        "# files.download('SA-CNBC.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ2g4FreBs7K"
      },
      "outputs": [],
      "source": [
        "# # Combine all mentioned keywords into a single string\n",
        "# keywords_combined = ' '.join(sentiment_data_cnbc['Keywords'].sum())\n",
        "\n",
        "# # Generate word cloud\n",
        "# wordcloud = WordCloud(width=800, height=400, background_color='white').generate(keywords_combined)\n",
        "\n",
        "# # Display the word cloud\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJU1oYeJ_G2B"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB5PeWtb_I1O"
      },
      "outputs": [],
      "source": [
        "# # Create an empty DataFrame to store sentiment data\n",
        "# sentiment_data_cnn = pd.DataFrame(columns=['Text', 'Compound Sentiment Score', 'Date', 'Keywords'])\n",
        "\n",
        "# # Create an empty list to store sentiment labels\n",
        "# sentiment_labels = []\n",
        "\n",
        "# # Iterate over the keywords\n",
        "# for keyword in kw:\n",
        "\n",
        "#     # Iterate over each row in the DataFrame\n",
        "#     for index, row in new_cnn.iterrows():\n",
        "#         # Extract the text and date from the row\n",
        "#         text = str(row['Text'])\n",
        "#         date_str = row['Date']\n",
        "\n",
        "#         # Perform sentiment analysis on the text\n",
        "#         sentiment = analyzer.polarity_scores(text)\n",
        "#         compound_score = sentiment[\"compound\"]\n",
        "\n",
        "#         # Check if the keyword is mentioned in the text\n",
        "#         mentioned_keywords = [kw for kw in keyword if kw.lower() in text.lower()]\n",
        "\n",
        "#         # Create a DataFrame for the current row\n",
        "#         row_data = pd.DataFrame({'Text': [text], 'Compound Sentiment Score': [compound_score], 'Date': [date_str],\n",
        "#                                  'Keywords': [mentioned_keywords]})\n",
        "\n",
        "#         # Concatenate the current row DataFrame with the sentiment_data DataFrame\n",
        "#         sentiment_data_cnn = pd.concat([sentiment_data_cnn, row_data], ignore_index=True)\n",
        "\n",
        "#         # Assign a label based on the compound score\n",
        "#         if compound_score >= 0.05:\n",
        "#             sentiment_labels.append('Positive')\n",
        "#         elif compound_score <= -0.05:\n",
        "#             sentiment_labels.append('Negative')\n",
        "#         else:\n",
        "#             sentiment_labels.append('Neutral')\n",
        "\n",
        "# # Add the sentiment labels to the DataFrame\n",
        "# sentiment_data_cnn['Sentiment Label'] = sentiment_labels\n",
        "\n",
        "# # Print the sentiment data DataFrame\n",
        "# # print(sentiment_data_cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P5dVhprM3rl"
      },
      "outputs": [],
      "source": [
        "# sentiment_data_cnn.to_csv('SA-CNN.csv',encoding='utf-8-sig')\n",
        "# files.download('SA-CNN.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W9Nx89fBqSR"
      },
      "outputs": [],
      "source": [
        "# # Combine all mentioned keywords into a single string\n",
        "# keywords_combined = ' '.join(sentiment_data_cnn['Keywords'].sum())\n",
        "\n",
        "# # Generate word cloud\n",
        "# wordcloud = WordCloud(width=800, height=400, background_color='white').generate(keywords_combined)\n",
        "\n",
        "# # Display the word cloud\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UIgQZmdEfC"
      },
      "source": [
        "## Mega plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5D0mKiodHV_"
      },
      "outputs": [],
      "source": [
        "cnn_sa = pd.read_csv('/content/SA-CNN.csv', error_bad_lines=False,  encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyaATP7PdZUs"
      },
      "outputs": [],
      "source": [
        "cnbc_sa = pd.read_csv('/content/SA-CNBC.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJrr6Nha0wMw"
      },
      "source": [
        "# Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chZO8CIo03VH"
      },
      "outputs": [],
      "source": [
        "# Distribution of Sentiments\n",
        "fig, axs = plt.subplots(len(super_sa), len(super_sa[0]), figsize=(12, 10))\n",
        "\n",
        "kws_names = ['Cor', 'AAPL', 'Pfi', 'MS', 'GOOG']\n",
        "source = ['CNBC', 'CNN', 'YSP', 'NYT']\n",
        "for i in range(len(super_sa)):\n",
        "    for j in range(len(super_sa[i])):\n",
        "        if i == 0 and j == 2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0, 1])\n",
        "          ax.set_xticks([-1,0, 1])\n",
        "        elif i==1 and j == 2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([ 5,15,25,35])\n",
        "        elif i==1 and j == 0:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([ 0,500,1000])\n",
        "        elif i==1 and j == 4:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0, 10,20])\n",
        "        elif i==2 and j == 2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0, 1])\n",
        "          ax.set_xticks([0,1])\n",
        "        elif i==2 and j == 3:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([ 5,15,25,35])\n",
        "          ax.set_xticks([0,0.5,1])\n",
        "        elif i==2 and j == 4:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([ 5,15,25,35])\n",
        "        elif i==3 and j == 4:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_xticks([-1,0,1])\n",
        "          ax.set_yticks([0,40,80])\n",
        "        elif i==3 and j == 0:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0, 3500,7000])\n",
        "        elif i==3 and j == 1:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,100,200])\n",
        "        elif i==3 and j==2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,40,80])\n",
        "        else:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment'].hist(ax=ax, grid=False,bins=5)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          # Set x-axis limits\n",
        "          # ax.set_xlim(-1, 1)\n",
        "\n",
        "# Set x-label and y-label for the entire plot\n",
        "fig.text(0.5, -.03, 'Sentiments', ha='center',fontsize=18)\n",
        "fig.text(-.03, 0.5, 'Frequency', va='center', rotation='vertical',fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.show()\n",
        "# plt.savefig('SA-Histogram.png',dpi=600, transparent=True,bbox_inches = 'tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgByH1u_08hS"
      },
      "outputs": [],
      "source": [
        "# for the Sentiment label\n",
        "fig, axs = plt.subplots(len(super_sa), len(super_sa[0]), figsize=(12, 10))\n",
        "\n",
        "kws_names = ['Cor', 'AAPL', 'Pfi', 'MS', 'GOOG']\n",
        "source = ['CNBC', 'CNN', 'YSP', 'NYT']\n",
        "for i in range(len(super_sa)):\n",
        "    for j in range(len(super_sa[i])):\n",
        "        if i == 0 and j == 2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,1,2])\n",
        "        elif i == 1 and j == 0:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,500,1000])\n",
        "        elif i == 1 and j == 2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,20,40])\n",
        "        elif i == 1 and j == 4:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,10,20])\n",
        "        elif i == 2 and j == 1:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,100,200])\n",
        "        elif i == 2 and j == 2:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,1])\n",
        "        elif i == 2 and j == 3:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,20,40])\n",
        "        elif i == 2 and j == 4:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "          ax.set_yticks([0,20,40])\n",
        "        else:\n",
        "          ax = axs[i, j]\n",
        "          super_sa[i][j]['Sentiment Label'].hist(ax=ax, grid=False)\n",
        "          ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "\n",
        "# Set x-label and y-label for the entire plot\n",
        "fig.text(0.5, -.03, 'Sentiment Label', ha='center',fontsize=18)\n",
        "fig.text(-.03, 0.5, 'Frequency', va='center', rotation='vertical',fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.show()\n",
        "plt.savefig('SA-Results.png',dpi=600, transparent=True,bbox_inches = 'tight')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCUfyt3H1D8h"
      },
      "source": [
        "# Financial Data and Sentiment Scores Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5Cy84c51ikI"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Convert the 'Date' column to DatetimeIndex\n",
        "date_index = pd.DatetimeIndex(super_sa[2][0]['Date'])\n",
        "\n",
        "# Plot the sentiment data as scatter plots\n",
        "ax2.plot(date_index, super_sa[2][0]['Sentiment'], 'ro', label='Sentiment Score')\n",
        "ax2.set_ylabel('Sentiment Score')\n",
        "ax2.set_ylim([-1, 1])  # Adjust the y-axis limits as needed\n",
        "\n",
        "ax1.plot(apl['Date'],apl['Close'],label='AAPL')\n",
        "ax1.plot(goog['Date'],goog['Close'],label='GOOG')\n",
        "ax1.plot(ms['Date'],ms['Close'],label='Microsoft')\n",
        "ax1.plot(pfe['Date'],pfe['Close'],label='Pfizer')\n",
        "\n",
        "\n",
        "\n",
        "# Combine the legends for both axes\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-I7nHtU1OlX"
      },
      "source": [
        "## Multiplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdTfuliO1Kb-"
      },
      "outputs": [],
      "source": [
        "print(apl['Date'].min())\n",
        "print(apl['Date'].max())\n",
        "a = apl['Date'][0]\n",
        "m = apl['Date'][378]\n",
        "e = apl['Date'][len(apl['Date'])-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAq56X8l1bFm"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(len(super_sa), len(super_sa[0]), figsize=(20, 10),sharex=True,sharey='row')\n",
        "ax2 = np.empty_like(ax1, dtype=object)\n",
        "\n",
        "# x ticks for the x axis\n",
        "a = apl['Date'][0]\n",
        "m = apl['Date'][378]\n",
        "e = apl['Date'][len(apl['Date'])-1]\n",
        "\n",
        "# Create empty lists to store legend handles and labels\n",
        "legend_handles = []\n",
        "legend_labels = []\n",
        "\n",
        "# for subtitles\n",
        "kws_names = ['Cor', 'AAPL', 'Pfi', 'MS', 'GOOG']\n",
        "source = ['CNBC', 'CNN', 'YSP', 'NYT']\n",
        "colors = ['red','dimgray','brown','indigo','olive']\n",
        "for i in range(len(super_sa)):\n",
        "    for j in range(len(super_sa[i])):\n",
        "\n",
        "        ax = ax1[i, j]\n",
        "        ax.plot(super_sa[i][j]['Date'], super_sa[i][j]['Sentiment'],'o',color=colors[j], label='Sentiment Score')\n",
        "        # ax.set_ylabel('Sentiment Score')\n",
        "        ax.set_ylim([-1, 1])\n",
        "        ax2[i, j] = ax.twinx()\n",
        "        ax2[i, j].plot(apl['Date'], apl['Close'], label='AAPL')\n",
        "        ax2[i, j].plot(goog['Date'], goog['Close'], label='GOOG')\n",
        "        # ax2[i, j].plot(ms['Date'], ms['Close'], label='Microsoft')\n",
        "        ax2[i, j].plot(pfe['Date'], pfe['Close'], label='Pfizer',color='black')\n",
        "\n",
        "        # date_ticks = apl['Date'].iloc[::len(apl['Date']) // 3]\n",
        "        ax.set_xticks([a,m,e])\n",
        "        ax.set_xticklabels([date.strftime('%Y-%m') for date in [a,m,e]], rotation=90)\n",
        "        ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "        handles, labels = ax.get_legend_handles_labels()\n",
        "        legend_handles.extend(handles)\n",
        "        legend_labels.extend(labels)\n",
        "\n",
        "        handles2, labels2 = ax2[i, j].get_legend_handles_labels()\n",
        "        legend_handles.extend(handles2)\n",
        "        legend_labels.extend(labels2)\n",
        "\n",
        "# Set x-label and y-label for the entire plot\n",
        "plt.subplots_adjust(wspace=0.5)  # Adjust the vertical spacing between subplots\n",
        "plt.legend(legend_handles[0:5], legend_labels[0:5],loc='upper center', bbox_to_anchor=(0.5, -0.5), ncol=2)\n",
        "\n",
        "fig.text(0.5, -.02, 'Date', ha='center',fontsize=18)\n",
        "fig.text(.07, 0.5, 'Sentiments', va='center', rotation='vertical',fontsize=18)\n",
        "fig.text(.93, 0.5, 'Price', va='center', rotation=270,fontsize=18)\n",
        "plt.savefig('Stock-Price-Sentimental.png',dpi=600, transparent=True,bbox_inches = 'tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQJejWWM1tl4"
      },
      "source": [
        "# Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iySJpis14jA"
      },
      "outputs": [],
      "source": [
        "# Changing data frames\n",
        "apl_df = apl[['Date','Close']]\n",
        "apl_df.index = range(len(apl_df))\n",
        "# print(type(apl_df))\n",
        "goog_df = goog[['Date','Close']]\n",
        "goog_df.index = range(len(apl_df))\n",
        "ms_df = ms[['Date','Close']]\n",
        "ms_df.index = range(len(apl_df))\n",
        "pfe_df = pfe[['Date','Close']]\n",
        "pfe_df.index = range(len(apl_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR-9w3_71-ur"
      },
      "outputs": [],
      "source": [
        "# super correlation list\n",
        "super_corr_lst = []\n",
        "\n",
        "# correlation multiplot\n",
        "for i in range(len(super_sa)):\n",
        "    correlation_one = []\n",
        "    for j in range(len(super_sa[i])):\n",
        "      # Sentiments\n",
        "      df_sa = super_sa[i][j][['Date','Sentiment']]\n",
        "      m_sa_df = df_sa.groupby('Date')['Sentiment'].mean().reset_index() # Calculate the mean sentiment for each unique date\n",
        "      m_sa_df.columns = ['Date', 'Sentiment'] # Rename the columns\n",
        "      m_sa_df['Date'] = pd.to_datetime(m_sa_df['Date'])\n",
        "      # print(m_sa_df['Sentiment'][0], 'Part 1')\n",
        "      m_index = []\n",
        "      mi_ind = []\n",
        "      # print(len(m_index))\n",
        "      # print(len(mi_ind))\n",
        "      for date1 in goog_df['Date']:\n",
        "        for date2 in m_sa_df['Date']:\n",
        "            if date1 == date2:\n",
        "                m_index.append(goog_df[goog_df['Date'] == date1].index[0])\n",
        "                mi_ind.append(m_sa_df[m_sa_df['Date'] == date2].index[0])\n",
        "      # New index\n",
        "      m_sa_df = m_sa_df.loc[mi_ind]\n",
        "      m_sa_df.index = range(len(m_sa_df))\n",
        "      apl_correlation = apl_df.loc[m_index]\n",
        "      apl_correlation.index = range(len(apl_correlation))\n",
        "      goog_correlation = goog_df.loc[m_index]\n",
        "      goog_correlation.index  = range(len(goog_correlation))\n",
        "      ms_correlation = ms_df.loc[m_index]\n",
        "      ms_correlation.index  = range(len(ms_correlation))\n",
        "      pfe_correlation = pfe_df.loc[m_index]\n",
        "      pfe_correlation.index  = range(len(pfe_correlation))\n",
        "      apl_correlation.rename(columns={'Close': 'AAPL'}, inplace=True)\n",
        "      goog_correlation.rename(columns={'Close': 'GOOG'}, inplace=True)\n",
        "      ms_correlation.rename(columns={'Close': 'MS'}, inplace=True)\n",
        "      pfe_correlation.rename(columns={'Close': 'Pfe'}, inplace=True)\n",
        "      m = m_sa_df['Sentiment']\n",
        "      a = apl_correlation['AAPL']\n",
        "\n",
        "      g = goog_correlation['GOOG']\n",
        "\n",
        "      ms = ms_correlation['MS']\n",
        "\n",
        "      pfe = pfe_correlation['Pfe']\n",
        "\n",
        "      merged_df = pd.concat([m, a, g, ms, pfe], axis=1)\n",
        "      cor_df = merged_df.corr()\n",
        "\n",
        "      # put in first list\n",
        "      correlation_one.append(cor_df)\n",
        "    super_corr_lst.append(correlation_one)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OITaYuo1BLCe"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(len(super_sa), len(super_sa[0]), figsize=(20, 10),sharex=True,sharey=True)\n",
        "\n",
        "kws_names = ['Cor', 'AAPL', 'Pfi', 'MS', 'GOOG']\n",
        "source = ['CNBC', 'CNN', 'YSP', 'NYT']\n",
        "\n",
        "labels = ['Sentiment','AAPL','GOOG','MS','Pfe']\n",
        "for i in range(len(super_corr_lst)):\n",
        "    for j in range(len(super_corr_lst[i])):\n",
        "        ax = axs[i, j]\n",
        "        # mask=mask,\n",
        "        sb.heatmap(super_corr_lst[i][j], fmt=\".2f\", annot=True, cmap='coolwarm', cbar=True, ax=ax)\n",
        "        ax.set_title(f'{source[i]}, {kws_names[j]}')\n",
        "        # plt.xticks(fontsize=12, rotation=60)\n",
        "        # plt.yticks(fontsize=12, rotation=0)\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.set_yticklabels(labels)\n",
        "\n",
        "\n",
        "\n",
        "plt.savefig('Correlation.png',dpi=600, transparent=True,bbox_inches = 'tight')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "s_YCRRRJrd9c"
      ],
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}