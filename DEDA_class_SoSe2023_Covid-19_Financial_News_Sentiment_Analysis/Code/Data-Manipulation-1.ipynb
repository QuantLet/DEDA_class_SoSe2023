{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fbbf90-23b8-4719-8a72-5950612680a8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882096f-bce9-4f75-9b7a-dcb79428cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets\n",
    "import opendatasets as od # for downloading data\n",
    "import pandas as pd # for handling data\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b161a-4134-4d15-9bc4-a20a3faa29fb",
   "metadata": {},
   "source": [
    "# Download Data from Kaggle\n",
    "as csv file to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf48c82-f676-4c33-8533-cf12fee46c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this method you need an account by Kaggle\n",
    "# Needs: username & key\n",
    "# for more information go to https://www.geeksforgeeks.org/how-to-import-kaggle-datasets-directly-into-google-colab/\n",
    "\n",
    "# one url\n",
    "nyt_url_kaggle = 'https://www.kaggle.com/datasets/aryansingh0909/nyt-articles-21m-2000-present'\n",
    "\n",
    "# downloading data\n",
    "download_cnbc = od.download('https://www.kaggle.com/datasets/thedevastator/cnbc-business-and-financial-news-dataset-450k')\n",
    "download_cnn = od.download('https://www.kaggle.com/datasets/hadasu92/cnn-articles-after-basic-cleaning')\n",
    "download_nyt  = od.download(nyt_url_kaggle)\n",
    "# yahoo data about apple\n",
    "download_ysp = od.download('https://www.kaggle.com/datasets/deepakjoshi2k/yahoo-stock-prediction-by-news')\n",
    "\n",
    "# make the downloads as Data Frames\n",
    "# directories:\n",
    "dsd_cnbc = './cnbc-business-and-financial-news-dataset-450k'\n",
    "dsd_cnn = './cnn-articles-after-basic-cleaning'\n",
    "dataset_directory_df_ysp = './yahoo-stock-prediction-by-news'\n",
    "dsd_nyt = 'nyt-articles-21m-2000-present'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_cnbc= pd.read_csv(f'{dsd_cnbc}/cnbc_news_datase.csv')\n",
    "df_cnn = pd.read_csv(f'{dsd_cnn}/CNN_Articels_clean/CNN_Articels_clean.csv')\n",
    "df_ysp = pd.read_csv(f'{dataset_directory_df_ysp}/NEWS_YAHOO_stock_prediction.csv')\n",
    "df_nyt = pd.read_csv(f'{dsd_nyt}/nyt-metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb79dc7-0393-4837-89ba-70dccdce069b",
   "metadata": {},
   "source": [
    "Different Method:\n",
    "https://www.geeksforgeeks.org/how-to-download-kaggle-datasets-into-jupyter-notebook/#:~:text=Step%201%3A%20Visit%20the%20Kaggle,Upload%20to%20Your%20Jupyter%20Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce305b-66f5-4ccb-9749-01f43c9baab4",
   "metadata": {},
   "source": [
    "# sorting after date and drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b5dad-aaa2-42b3-85e1-5a43e7f3a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by date\n",
    "df_cnn = df_cnn.sort_values(by='Date published')\n",
    "df_cnbc = df_cnbc.sort_values(by='published_at')\n",
    "df_ysp = df_ysp.sort_values(by='Date')\n",
    "df_nyt = df_nyt.sort_values(by='pub_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbc7c6-9bef-439c-ba6b-6b71e8afc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting all not necessary rows\n",
    "df_nyt = df_nyt.drop(['print_section',\n",
    "                 'print_page', 'source',\n",
    "                 'multimedia', 'news_desk',\n",
    "                 'section_name', '_id',\n",
    "                 'word_count',\n",
    "                 'subsection_name', 'uri', 'document_type','byline',\n",
    "                      'type_of_material'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1c1b3-1284-43dd-b410-c122c46231ae",
   "metadata": {},
   "source": [
    "# Drop not necessary data like years before 2020 and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4a9ba-e820-4c5f-bc7f-a32bff7a6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for our project we need the data from the years 2020, 2021 and 2022\n",
    "\n",
    "# new df index for drop the years out from 3 of 4 data frames (df)\n",
    "ni_cnn = range(len(df_cnn))\n",
    "ni_cnbc = range(len(df_cnbc))\n",
    "ni_ysp = range(len(df_ysp))\n",
    "ni = range(len(df_nyt))\n",
    "\n",
    "df_cnn.index = ni_cnn\n",
    "df_cnbc.index = ni_cnbc\n",
    "df_ysp.index = ni_ysp\n",
    "df_nyt.index = ni\n",
    "\n",
    "# For this we filtering the data frame\n",
    "ind_nyt = []\n",
    "for i in range(len(df_nyt)):\n",
    "    dt_str = df_nyt.at[i,'pub_date']\n",
    "    if isinstance(dt_str, str):\n",
    "    if dt_str == 'Sports':\n",
    "        pass\n",
    "    else: \n",
    "        dt_obj = dt.datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S%z')\n",
    "        year = int(dt_obj.year)\n",
    "        if year == 2020 or year == 2021 or year == 2022:\n",
    "            ind_nyt.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# producing\n",
    "# for nyt\n",
    "ind_nyt_20 = []\n",
    "ind_nyt_21 = []\n",
    "ind_nyt_22 = []\n",
    "for i in range(len(df_nyt)):\n",
    "    dt_str = df_nyt.at[i,'pub_date']\n",
    "    if isinstance(dt_str, str):\n",
    "        if dt_str == 'Sports':\n",
    "              pass\n",
    "    else:\n",
    "        dt_obj = dt.datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S%z')\n",
    "        year = int(dt_obj.year)\n",
    "        if year == 2020:\n",
    "            ind_nyt_20.append(i)\n",
    "        elif year == 2021:\n",
    "            ind_nyt_21.append(i)\n",
    "        elif year == 2022:\n",
    "            ind_nyt_22.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# for cnn:\n",
    "ind_cnn = []\n",
    "for i in range(len(df_cnn)):\n",
    "    dt_str = df_cnn.at[i,'Date published']\n",
    "    dt_obj = dt.datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S')\n",
    "    year = int(dt_obj.year)\n",
    "    if year == 2020 or year == 2021 or year == 2022:\n",
    "        ind_cnn.append(i)\n",
    "\n",
    "# for cnbc\n",
    "ind_cnbc = []\n",
    "for i in range(len(df_cnbc)):\n",
    "    dt_str = df_cnbc.at[i,'published_at']\n",
    "    dt_obj = dt.datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    year = int(dt_obj.year)\n",
    "    if year == 2020 or year == 2021 or year == 2022:\n",
    "        ind_cnbc.append(i)\n",
    "\n",
    "# for yahoo a\n",
    "ind_ysp = []\n",
    "for i in range(len(df_ysp)):\n",
    "    dt_str = df_ysp.at[i,'Date']\n",
    "    dt_obj = dt.datetime.strptime(dt_str, \"%Y-%m-%d\")\n",
    "    year = int(dt_obj.year)\n",
    "    if year == 2020 or year == 2021 or year == 2022:\n",
    "        ind_ysp.append(i)\n",
    "\n",
    "# droping out all dates without the years 2020,2021 and 2022\n",
    "df_nyt20 = df_nyt.loc[ind_nyt_20] # for 2020\n",
    "df_nyt21 = df_nyt.loc[ind_nyt_21] # for 2021\n",
    "df_nyt22 = df_nyt.loc[ind_nyt_22] # for 2022\n",
    "df_cnn   = df_cnn.loc[ind_cnn]\n",
    "df_cnbc  = df_cnbc.loc[ind_cnbc]\n",
    "df_ysp   = df_ysp.loc[ind_ysp]\n",
    "\n",
    "# New index:\n",
    "ni_nyt = range(len(df_nyt))\n",
    "ni_cnn = range(len(df_cnn))\n",
    "ni_cnbc = range(len(df_cnbc))\n",
    "ni_ysp = range(len(df_ysp))\n",
    "\n",
    "df_nyt.index = ni_nyt\n",
    "df_cnn.index = ni_cnn\n",
    "df_cnbc.index = ni_cnbc\n",
    "df_ysp.index = ni_ysp\n",
    "\n",
    "# Drop the rows that we don't need\n",
    "df_nyt = df_nyt.drop(['print_section', \n",
    "                 'print_page', 'source', \n",
    "                 'multimedia', 'news_desk', \n",
    "                 'section_name', '_id', \n",
    "                 'word_count', \n",
    "                 'subsection_name', 'uri', 'document_type','byline',\n",
    "                      'type_of_material'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea26b3c-3aed-4e31-8a4c-e23426756250",
   "metadata": {},
   "source": [
    "Now is the data frame ready to use. The data frame can be found as csv file on github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a2ebe-b7c0-46c9-bc3d-c2222f1b5090",
   "metadata": {},
   "source": [
    "# Download the data on local computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cff670-84fe-44ba-b284-fa1235490fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYT Data\n",
    "df_nyt.to_csv('NYT20-22.csv', encoding = 'utf-8-sig') \n",
    "files.download('NYT20-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdfcb4-5103-44cb-89ea-37c3cff62df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Data\n",
    "df_cnn.to_csv('CNN.csv', encoding = 'utf-8-sig')\n",
    "files.download('CNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d349f-211e-4d30-a448-c1030a864df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNBC Data\n",
    "df_cnbc.to_csv('CNBC.csv', encoding = 'utf-8-sig')\n",
    "files.download('CNBC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b7355-52a9-45fc-83d9-ca248bb04122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo Data\n",
    "df_ysp.to_csv('ysp.csv', encoding = 'utf-8-sig')\n",
    "files.download('ysp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
